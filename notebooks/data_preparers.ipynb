{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Configuration Format of Text\n",
    "The initial format, at least for workability will need to be a list of words and punctuation. Getting into this format will be the first step of configuration that the text will undergo as it is simplest when trying to create a dictionary.\n",
    "\n",
    "#### Example Text (Emma):\n",
    "Using the `nltk` library (and for simplicity's sake) we will read in Jane Austen's *Emma*, which can conveniently be loaded in as a list of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
     ]
    }
   ],
   "source": [
    "print(nltk.corpus.gutenberg.fileids())\n",
    "emma = nltk.corpus.gutenberg.words('austen-emma.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[',\n",
       " 'Emma',\n",
       " 'by',\n",
       " 'Jane',\n",
       " 'Austen',\n",
       " '1816',\n",
       " ']',\n",
       " 'VOLUME',\n",
       " 'I',\n",
       " 'CHAPTER',\n",
       " 'I',\n",
       " 'Emma',\n",
       " 'Woodhouse',\n",
       " ',',\n",
       " 'handsome',\n",
       " ',',\n",
       " 'clever',\n",
       " ',',\n",
       " 'and',\n",
       " 'rich']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first 20 words/punctuations of emma\n",
    "emma[0: 20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "Once we have the corpus in a list, we need to provide some preprocessing options that can prepare the data for being loaded up into a neural net. Again, these are just options and could potentially improve performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(corpus_list, lowercase=False, stopwords_list=None):\n",
    "    \"\"\"Preprocess the Corpus List.\n",
    "    \n",
    "    Provides some simple preprocessing steps that could be beneficial for training purposes. This includes \n",
    "    an option to lowercase all words in the corpus list and to remove stopwords.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    corpus_list: list\n",
    "        List of words in the corpus.\n",
    "        \n",
    "    lowercase: bool\n",
    "        Option to lowercase all words int he corpus_list.\n",
    "        \n",
    "    stopwords_list: list\n",
    "        List of stopwords to remove from the corpus_list.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    corpus_list: list\n",
    "        The preprocessed corpus_list.\n",
    "    \"\"\"\n",
    "    \n",
    "    # lowercases words in corpus\n",
    "    if lowercase:\n",
    "        corpus_list = [w.lower() for w in corpus_list]\n",
    "    \n",
    "    # removes stopwords\n",
    "    if stopwords_list is not None:\n",
    "        corpus_list = [w for w in corpus_list if w not in stopwords_list]\n",
    "        \n",
    "    return corpus_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[',\n",
       " 'by',\n",
       " 'jane',\n",
       " 'austen',\n",
       " '1816',\n",
       " ']',\n",
       " 'i',\n",
       " 'chapter',\n",
       " 'i',\n",
       " 'woodhouse',\n",
       " ',',\n",
       " 'handsome',\n",
       " ',',\n",
       " 'clever',\n",
       " ',',\n",
       " 'and',\n",
       " 'rich']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(emma[0:20], lowercase=True, stopwords_list= ['emma', 'volume'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary Dictionary\n",
    "Neural nets don't take text inputs so we need to convert the words into integers that act as key references back to the words. `create_dictionary` is this step in the process and provides a dictionary where the word acts as the key and the integer is the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dictionary(corpus_list, lowercase=False, stopwords_list=None):\n",
    "    \"\"\"Create a Vocabulary Dictionary.\n",
    "    \n",
    "    Create a dictionary of the vocab from a list of words in a corpus. This function\n",
    "    all so provides the option to preprocess on the fly.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    corpus_list: list\n",
    "        List of words in the corpus.\n",
    "        \n",
    "    lowercase: bool\n",
    "        Option to lowercase all words int he corpus_list.\n",
    "        \n",
    "    stopwords_list: list\n",
    "        List of stopwords to remove from the corpus_list.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    vocab_dict: tuple\n",
    "        A vocabulary dictionary => {word: int} and a reverse dictionary => {int: word}.\n",
    "    \"\"\"\n",
    "    \n",
    "    corpus_list = preprocess(corpus_list, lowercase=lowercase, stopwords_list=stopwords_list)\n",
    "    \n",
    "    uniq_words = list(set(corpus_list))\n",
    "    word_indexes = list(range(0, len(uniq_words)))\n",
    "    \n",
    "    vocab_dict = dict(zip(uniq_words, word_indexes))\n",
    "    reverse_dict = dict(zip(word_indexes, uniq_words))\n",
    "    \n",
    "    return vocab_dict, reverse_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1816': 6,\n",
       " '[': 9,\n",
       " ']': 10,\n",
       " 'and': 3,\n",
       " 'austen': 2,\n",
       " 'by': 7,\n",
       " 'chapter': 0,\n",
       " 'clever': 12,\n",
       " 'emma': 11,\n",
       " 'handsome': 13,\n",
       " 'i': 1,\n",
       " 'jane': 14,\n",
       " 'rich': 5,\n",
       " 'volume': 8,\n",
       " 'woodhouse': 4}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_dictionary(emma[0:20], lowercase=True, stopwords_list=[','])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_lists = []\n",
    "for i in range(0, len(emma) - 3):\n",
    "    config_lists.append(list(emma[i: i + 4]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192427"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(emma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['[', 'Emma', 'by', 'Jane'],\n",
       "       ['Emma', 'by', 'Jane', 'Austen'],\n",
       "       ['by', 'Jane', 'Austen', '1816'],\n",
       "       ...,\n",
       "       ['happiness', 'of', 'the', 'union'],\n",
       "       ['of', 'the', 'union', '.'],\n",
       "       ['the', 'union', '.', 'FINIS']], dtype='<U17')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(config_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
